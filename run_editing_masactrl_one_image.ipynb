{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "\n",
    "from diffusers import DDIMScheduler\n",
    "\n",
    "from models.p2p.inversion import DirectInversion\n",
    "from models.masactrl.diffuser_utils import MasaCtrlPipeline\n",
    "from models.masactrl.masactrl_utils import AttentionBase\n",
    "from models.masactrl.masactrl_utils import regiter_attention_editor_diffusers\n",
    "from models.masactrl.masactrl import MutualSelfAttentionControl\n",
    "from utils.utils import load_512,txt_draw\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from run_editing_masactrl import MasaCtrlEditor\n",
    "\n",
    "\n",
    "\n",
    "def mask_decode(encoded_mask,image_shape=[512,512]):\n",
    "    length=image_shape[0]*image_shape[1]\n",
    "    mask_array=np.zeros((length,))\n",
    "    \n",
    "    for i in range(0,len(encoded_mask),2):\n",
    "        splice_len=min(encoded_mask[i+1],length-encoded_mask[i])\n",
    "        for j in range(splice_len):\n",
    "            mask_array[encoded_mask[i]+j]=1\n",
    "            \n",
    "    mask_array=mask_array.reshape(image_shape[0], image_shape[1])\n",
    "    # to avoid annotation errors in boundary\n",
    "    mask_array[0,:]=1\n",
    "    mask_array[-1,:]=1\n",
    "    mask_array[:,0]=1\n",
    "    mask_array[:,-1]=1\n",
    "            \n",
    "    return mask_array\n",
    "\n",
    "\n",
    "def setup_seed(seed=1234):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masactrl_editor=MasaCtrlEditor([\"ddim+masactrl\",\"directinversion+masactrl\"], torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddim+masactrl\n",
    "\n",
    "edited_image = masactrl_editor(\"ddim+masactrl\",\n",
    "                    image_path=\"scripts/example_cake.jpg\",\n",
    "                    prompt_src=\"a round cake with orange frosting on a wooden plate\",\n",
    "                    prompt_tar=\"a square cake with orange frosting on a wooden plate\",\n",
    "                    guidance_scale=7.5,\n",
    "                    step=4,\n",
    "                    layper=10\n",
    "                    )\n",
    "\n",
    "print(\"null-text-inversion+masactrl\")\n",
    "display(edited_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directinversion(ours)+p2p\n",
    "\n",
    "edited_image = masactrl_editor(\"directinversion+masactrl\",\n",
    "                    image_path=\"scripts/example_cake.jpg\",\n",
    "                    prompt_src=\"a round cake with orange frosting on a wooden plate\",\n",
    "                    prompt_tar=\"a square cake with orange frosting on a wooden plate\",\n",
    "                    guidance_scale=7.5,\n",
    "                    step=4,\n",
    "                    layper=10\n",
    "                    )\n",
    "\n",
    "print(\"directinversion(ours)+masactrl\")\n",
    "display(edited_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddim+masactrl\n",
    "\n",
    "edited_image = masactrl_editor(\"ddim+masactrl\",\n",
    "                    image_path=\"scripts/example_cat.jpg\",\n",
    "                    prompt_src=\"a cat sitting on a table with a green eyes\",\n",
    "                    prompt_tar=\"a watercolor of a cat sitting on a table with a green eyes\",\n",
    "                    guidance_scale=7.5,\n",
    "                    step=4,\n",
    "                    layper=10\n",
    "                    )\n",
    "\n",
    "print(\"null-text-inversion+masactrl\")\n",
    "display(edited_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directinversion+masactrl\n",
    "\n",
    "edited_image = masactrl_editor(\"directinversion+masactrl\",\n",
    "                    image_path=\"scripts/example_cat.jpg\",\n",
    "                    prompt_src=\"a cat sitting on a table with a green eyes\",\n",
    "                    prompt_tar=\"a watercolor of a cat sitting on a table with a green eyes\",\n",
    "                    guidance_scale=7.5,\n",
    "                    step=4,\n",
    "                    layper=10\n",
    "                    )\n",
    "\n",
    "print(\"directinversion(ours)+masactrl\")\n",
    "display(edited_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
